### process
- 운영체제로부터 메모리를 할당받아 컴퓨터에서 실행중인 프로그램
### thread
- 프로세스 내에서 공유되는 메모리를 바탕으로 생성하는 작업의 실행 단위
### thread safe
- 하나의 스레드가 자원에 접근하여 작업을 수행하는 상태
### race condition
- 여러 스레드가 하나의 공유 자원에 동시에 접근하면서 발생하는 문제
### mutex
- 공유 자원에 하나의 스레드만 진입하여 작업을 처리할 수 있도록 하는 lock 개념
### garbage collection
- 동적으로 할당했던 메모리 영역 중, 필요없게 된 영역을 해제한다.
- 파이썬을 reference counting
### context swiching 
- 사용중이던 context(프로세스/스레드)를 저장하고 다른 context 실행
  

---  
# GIL(Global Interface Lock)
- 파이썬 코드가 한 번에 하나의 스레드만 실행될 수 있도록 하는 mutex
``` python
def sum(x,y):
    return x+y

thread1=sum(1,2)
thread2=sum(3,4)
''' 
함수를 실행하는데 1초가 걸린다고 하면, 두 스레드가 완료되는 시점은 2초가 지난 뒤이다.
context swiching하는데 시간이 걸리고, 멀티스레딩 작업이 제한된다.
파이썬이 다른 언어보다 속도가 느린 이유이다.
'''
```
# 파이썬이 GIL을 만든 이유
- 파이썬은 **garbage collection(gc)**라는 메모리 관리 정책을 사용한다.  
 동적으로 할당된 데이터가 필요없어지면 메모리 할당을 해지하는 것입니다.  
 파이썬에서는 모든 것이 객체입니다.  
 파이썬은 객체에 대해 reference count(참조 변수)를 저장합니다.  
 그래서 각 객체가 참조된 횟수를 저장하는데 이게 0이 되면 파이썬의 gc가 그 객체를 메모리에서 삭제시킵니다.
- 이러한 garbage collection을 제대로 동작시키려면 thread-safe한 환경을 만들어야 한다.  
그래서 여러 스레드가 동일한 자원에 대해 접근하여, 데이터 무결성을 망가뜨릴 수 있는 race condition 상태를 피하기 위해 GIL을 만든 것이다.

``` python 
import sys

# x의 참조 횟수 : 1 
x=[]

# x의 참조 횟수 : 2 
y=x

# getrefcount(x) 호출하면 x의 참조 횟수가 3(1 증가)이 되었다가, 함수를 반환하면 2(1 감소)됨
sys.getrefcount(x)

# 출력 결과 : 3
```
``` python
import threading
import time
start=time.time()
x=0
def foo():
    global x
    for _ in range(1000000):
        x+=1
thread1=threading.Thread(target=foo)
thread2=threading.Thread(target=foo)

thread1.start()
thread2.start()


thread1.join()
thread2.join()

end=time.time()
print(f'x : {x}')
print(f'time : {end-start}')
'''
x : 1464429
time : 0.30333828926086426
100만을 더하는 함수를 2번 돌렸으니 200만이 나와야 하는, x갑은 그 보다 못한 수가 나온다.
race condition, 즉 여러 스레드가 하나의 자원에 접근해서 꼬여버린 것이다.
'''
```
### Lock 걸기
``` python
import threading
import time
start=time.time()
Lock=threading.Lock()
x=0
def foo():
    Lock.acquire()
    global x
    for _ in range(1000000):
        x+=1
    Lock.release()
    
thread1=threading.Thread(target=foo)
thread2=threading.Thread(target=foo)

thread1.start()
thread2.start()


thread1.join()
thread2.join()

end=time.time()
print(f'x : {x}')
print(f'time : {end-start}')
'''
x : 2000000
time : 0.2238306999206543
제대로 200만이 나온다. 속도도 더 빨라졌다! 
'''
```
# 그래서 파이썬에서 multi thread는 느릴 수 밖에 없나?
``` python
import time
import threading

def loop():
    for i in range(50000000):
        pass

# Single Thread
start = time.time()
loop()
loop()
end = time.time()
print('[Single Thread] total time : {}'.format(end - start))

# Multi Thread
start = time.time()
thread1 = threading.Thread(target=loop)
thread2 = threading.Thread(target=loop)
thread1.start()
thread2.start()
thread1.join()
thread2.join()
end = time.time()
print('[Multi Thread] total time : {}'.format(end - start))
'''
[Single Thread] total time : 1.4643371105194092
[Multi Thread] total time : 3.992478132247925

멀티 스레딩을 하니 오히려 느려진다.
'''
```
``` python
import time
import threading

def sleep_for_2s():
    time.sleep(2)

# Single Thread
start = time.time()
sleep_for_2s()
sleep_for_2s()
end = time.time()
print('[Single Thread] total time : {}'.format(end - start))

# Multi Thread
start = time.time()
thread1 = threading.Thread(target=sleep_for_2s)
thread2 = threading.Thread(target=sleep_for_2s)
thread1.start()
thread2.start()
thread1.join()
thread2.join()
end = time.time()
print('[Multi Thread] total time : {}'.format(end - start))
'''
[Single Thread] total time : 4.0045928955078125
[Multi Thread] total time : 2.003958225250244
멀티스레딩을 한 게 더 빠르다.
'''
```
- cpu 연산(계산 작업)은 멀티스레드 성능이 싱글스레드보다 떨어지게 될 수 있다.
- 하지만, i/o 작업이 큰 비중을 차지하거나, sleep으로 일정 시간 대기해야 하는 경우 멀티스레딩이 더 좋은 성능을 보이게 됩니다.  
입력 대기 시간이나 sleep으로 대기하는 동안 스레드는 GIL을 해제하고 context swiching이 일어나 다른 스레드가 실행될 수 있기 때문이다.
---
+ > https://medium.com/dmsfordsm/garbage-collection-in-python-777916fd3189
+ > 파이썬 메모리 저장 방식 더 공부




